{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You will need to store your db credentials in a file in a dictionary named \"creds\"\n",
    "exec(open('./db.cred').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://{user}:{password}@{host}/{dbname}', echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"dbname='{dbname}' user='{user}' host='{host}' password='{password}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_news['file_name'] = local_news['name'].map(lambda x: x.lower().replace(' ', '_') + '.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRss(file_name):\n",
    "    try:\n",
    "        with open('./front_pages/%s' % file_name) as f:\n",
    "            bs = BeautifulSoup(f, 'html.parser')\n",
    "            return bs.find_all('link', {'type': 'application/rss+xml'})[0]['href']\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#local_news[~local_news.rss_link.isnull()].to_pickle('rss_links.pkl')\n",
    "# Some code--getting the rss links from the local copies of their html homepages and updating it in the db--got lost here\n",
    "# but it's all in the local_news table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just the ones with rss links\n",
    "local_news = local_news[~local_news.rss_link.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all hashes postitive\n",
    "def posHash(x):\n",
    "    h = hash(x)\n",
    "    if h < 0:\n",
    "          return h + sys.maxsize\n",
    "    return h\n",
    "\n",
    "def getArticles(row):\n",
    "    # this is a bug many sites seem to have--including this line prevents any news articles from being included\n",
    "    rss_link = row['rss_link'].replace('&k[]=%23topstory', '')\n",
    "    r = requests.get(rss_link)\n",
    "    bs = BeautifulSoup(r.text, 'html5lib')\n",
    "    articles = pd.DataFrame([(item.find('title').text, \n",
    "      item.find('pubdate').text,\n",
    "      item.find('description').text,\n",
    "      item.find('link').next_element.strip(),\n",
    "     )\n",
    "    for item in bs.find_all('item')], columns=['headline', 'pub_date', 'description', 'link'])\n",
    "    \n",
    "    articles['pub_date'] = pd.to_datetime(articles['pub_date'])\n",
    "    articles['pub_name'] = row['name']\n",
    "    articles['pub_id'] = row['id']\n",
    "    \n",
    "    # the primary id for the rss_articles table is the positive \n",
    "    # hash of the concatinated pub_name and headline\n",
    "    articles['id'] = articles.apply(lambda x: posHash(x['pub_name'] + x['headline']), axis=1)\n",
    "    \n",
    "    # drop duplicates\n",
    "    return articles[~articles.duplicated('id', keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have no idea how duplicates got in the local news table... todo: fix this\n",
    "rss_news = local_news[local_news.rss_link != 'None'].drop_duplicates('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the rss links don't include the base url\n",
    "def addBaseUrl(row):\n",
    "    if notrow['url'] in row['rss_link']:\n",
    "            return row['url']\n",
    "    return row['url'] + row['rss_link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "rss_news['rss_link'] = rss_news.apply(lambda x: x['rss_link'] if 'http' in x['rss_link'] else x['url'] + x['rss_link'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "logfile = open('pull_rss.log', 'w')\n",
    "errorfile = open('pull_rss.error', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [00:59,  2.94it/s]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"DROP TABLE IF EXISTS rss_articles\")\n",
    "conn.commit()\n",
    "\n",
    "for i, row in tqdm(enumerate(rss_news.iterrows())):\n",
    "    try:\n",
    "        articles = getArticles(row[1])\n",
    "        if i == 0:\n",
    "            articles.to_sql('rss_articles', engine, if_exists='replace', index=False)\n",
    "            cur.execute(\"ALTER TABLE rss_articles ADD PRIMARY KEY (id)\")\n",
    "            conn.commit()\n",
    "        else:\n",
    "            articles.to_sql('rss_articles', engine, if_exists='append', index=False)\n",
    "        logfile.write(\"Pulled %d articles for %s\\n\" % (len(articles), row[1]['name']))\n",
    "        logfile.flush()\n",
    "    except:\n",
    "        errorfile.write(\"Error pulling articles from %s\\n\" % row[1]['rss_link'])\n",
    "        errorfile.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
