{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get names of newspapers from the newseum's website\n",
    "newseum = \"http://www.newseum.org/todaysfrontpages/?tfp_display=list&tfp_region=USA&tfp_sort_by=state\"\n",
    "page = urllib.request.urlopen(newseum)\n",
    "root = BeautifulSoup(page, 'html.parser')\n",
    "res = root.find_all('a', {'class': 'tfp-list-link'})\n",
    "names = [x.text.split('\\n')[1] for x in res]\n",
    "links = [x['href'] for x in res]\n",
    "loc_name = [x.find('h6').text for x in res]\n",
    "city_name = [x.split(',')[0] for x in loc_name]\n",
    "state_name = [re.findall(', ([A-Za-z. ]*)', x)[0][:-4] for x in loc_name]\n",
    "local_news = pd.DataFrame(list(zip(names, links, city_name, state_name)), columns=['name', 'link', 'city', 'state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_map = \"\"\"Alaska\tAK\n",
    "Ala.\tAL\n",
    "Ark.\tAR\n",
    "Ariz.\tAZ\n",
    "Calif.\tCA\n",
    "Colo.\tCO\n",
    "Conn.\tCT\n",
    "D.C.\tDC\n",
    "Del.\tDE\n",
    "Fla.\tFL\n",
    "Ga.\tGA\n",
    "Hawaii\tHI\n",
    "Iowa\tIA\n",
    "Idaho\tID\n",
    "Ill.\tIL\n",
    "Ind.\tIN\n",
    "Kan.\tKS\n",
    "Ky.\tKY\n",
    "La.\tLA\n",
    "Mass.\tMA\n",
    "Md.\tMD\n",
    "Maine\tME\n",
    "Mich.\tMI\n",
    "Minn.\tMN\n",
    "Mo.\tMO\n",
    "Miss.\tMS\n",
    "Mont.\tMT\n",
    "N.C.\tMC\n",
    "N.D.\tND\n",
    "Neb.\tNE\n",
    "N.H.\tNH\n",
    "N.J.\tNJ\n",
    "N.M.\tNM\n",
    "Nev.\tNV\n",
    "N.Y.\tNY\n",
    "Ohio\tOH\n",
    "Okla.\tOK\n",
    "Ore.\tOR\n",
    "Pa.\tPA\n",
    "R.I.\tRI\n",
    "S.C.\tSC\n",
    "S.D.\tSD\n",
    "Tenn.\tTN\n",
    "Texas\tTX\n",
    "Utah\tUT\n",
    "Va.\tVA\n",
    "Vt.\tVT\n",
    "Wash.\tWA\n",
    "Wis.\tWI\n",
    "W. Va.\tWV\n",
    "Wyo.\tWY\"\"\"\n",
    "\n",
    "state_map = dict(zip([x.split('\\t')[0] for x in state_map.split('\\n')], [x.split('\\t')[1] for x in state_map.split('\\n')]))\n",
    "local_news['state_code'] = local_news['state'].map(lambda x: state_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOuterLink(newseum_link):\n",
    "    try:\n",
    "        newseum_link = \"http://www.newseum.org/\" + newseum_link\n",
    "        x = urllib.request.urlopen(newseum_link)\n",
    "        x = BeautifulSoup(x, 'html.parser')\n",
    "        return x.find_all('span', {'class': 'fa fa-external-link'})[0].parent['href']\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "local_news['outer_links'] = local_news['link'].map(getOuterLink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_news.to_csv('./local_news.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You will need to store your db credentials in a file in a dictionary named \"creds\"\n",
    "exec(open('./db.cred').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://{user}:{password}@{host}/{dbname}'.format(**creds)\n",
    "                       , echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_news.columns = ['name', 'link', 'city', 'state', 'url', 'state_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_news['id'] = local_news.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_news[['name', 'city', 'state_code', 'url' ]].to_sql(name='local_news', con=engine, if_exists='replace', \n",
    "                                                          index=True, index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"dbname='{dbname}' user='{user}' host='{host}' password='{password}'\".format(**creds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make these directories\n",
    "FRONT_PAGES = './front_pages'\n",
    "OP_EDS = './op_eds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHeadline(link, file_name):\n",
    "    r = requests.get(link, allow_redirects=True)\n",
    "    open('%s/%s' % (FRONT_PAGES, file_name), 'wb').write(r.content)\n",
    "\n",
    "def getOpinion(link, file_name):\n",
    "    r = requests.get(link + '/opinion', allow_redirects=True)\n",
    "    open('%s/%s' % (OP_EDS, file_name), 'wb').write(r.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "logfile = open('pull_pages.log', 'w')\n",
    "errorfile = open('pull_pages.error', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:01,  2.82it/s]\n"
     ]
    }
   ],
   "source": [
    "for x in tqdm(sample.iterrows()):\n",
    "    link = x[1]['outer_links']\n",
    "    name = x[1]['name']\n",
    "    try:\n",
    "        getHeadline(link, name.lower().replace(' ', '_') + '.html')\n",
    "    except:\n",
    "        errorfile.write('Missed headline for %s\\n' % name)\n",
    "    try:\n",
    "        getOpinion(link, name.lower().replace(' ', '_') + '.html')\n",
    "    except:\n",
    "        errorfile.write('Missed opeds for %s\\n' % name)\n",
    "    errorfile.flush()\n",
    "    logfile.write(\"%s\\n\" % name)\n",
    "    logfile.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
